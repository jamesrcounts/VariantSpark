{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VariantSpark-k Medium Parquet\n",
    " - 5,000 samples  \n",
    " - 100,000,000 variables   \n",
    " - ?? minutes to run\n",
    " \n",
    " Realistic production-sized job (217 GB) - takes < ?? minutes to run w/ 4 qty of r4.4xlarge EC2 instance & Kubernetes\n",
    " \n",
    " NOTE: Two trial runs have completed in the notebook, but NOT returned '0', also the pods had to be stopped manually and did NOT return any results.\n",
    "\n",
    "### Parameters\n",
    " - input bucket location - CSIRO S3 bucket (Sydney)\n",
    " - input files `data_s5000_v100000000...` and fc `resp`\n",
    " - number of Spark executors 56 w/ 7 GB RAM each\n",
    " - number of RF trees 500, w/ batch of 28\n",
    " - file type is `-it parquet`\n",
    " - default `mtry`\n",
    " - calculate OOB as `-ro` paramater is configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-16 08:42:26 WARN  DriverServiceBootstrapStep:66 - Driver's hostname would preferably be variantsparkmediumparquet-58d581b28f653df791a7ce79e21d9628-driver-svc, but this is too long (must be <= 63 characters). Falling back to use spark-1537087346159-driver-svc as the driver service's name.\n",
      "2018-09-16 08:42:27 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state: \n",
      "\t pod name: variantsparkmediumparquet-58d581b28f653df791a7ce79e21d9628-driver\n",
      "\t namespace: default\n",
      "\t labels: spark-app-selector -> spark-d0fa92b7b49d44799f3cfb1e2e82e5f1, spark-role -> driver\n",
      "\t pod uid: 707fffa6-b98c-11e8-8a8e-0a0cd35f5fb0\n",
      "\t creation time: 2018-09-16T08:42:26Z\n",
      "\t service account name: spark\n",
      "\t volumes: spark-init-properties, download-jars-volume, download-files-volume, spark-token-l2lzk\n",
      "\t node name: N/A\n",
      "\t start time: N/A\n",
      "\t container images: N/A\n",
      "\t phase: Pending\n",
      "\t status: []\n",
      "2018-09-16 08:42:27 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state: \n",
      "\t pod name: variantsparkmediumparquet-58d581b28f653df791a7ce79e21d9628-driver\n",
      "\t namespace: default\n",
      "\t labels: spark-app-selector -> spark-d0fa92b7b49d44799f3cfb1e2e82e5f1, spark-role -> driver\n",
      "\t pod uid: 707fffa6-b98c-11e8-8a8e-0a0cd35f5fb0\n",
      "\t creation time: 2018-09-16T08:42:26Z\n",
      "\t service account name: spark\n",
      "\t volumes: spark-init-properties, download-jars-volume, download-files-volume, spark-token-l2lzk\n",
      "\t node name: ip-10-0-101-78.us-west-2.compute.internal\n",
      "\t start time: N/A\n",
      "\t container images: N/A\n",
      "\t phase: Pending\n",
      "\t status: []\n",
      "2018-09-16 08:42:27 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state: \n",
      "\t pod name: variantsparkmediumparquet-58d581b28f653df791a7ce79e21d9628-driver\n",
      "\t namespace: default\n",
      "\t labels: spark-app-selector -> spark-d0fa92b7b49d44799f3cfb1e2e82e5f1, spark-role -> driver\n",
      "\t pod uid: 707fffa6-b98c-11e8-8a8e-0a0cd35f5fb0\n",
      "\t creation time: 2018-09-16T08:42:26Z\n",
      "\t service account name: spark\n",
      "\t volumes: spark-init-properties, download-jars-volume, download-files-volume, spark-token-l2lzk\n",
      "\t node name: ip-10-0-101-78.us-west-2.compute.internal\n",
      "\t start time: 2018-09-16T08:42:26Z\n",
      "\t container images: jamesrcounts/variantspark:002\n",
      "\t phase: Pending\n",
      "\t status: [ContainerStatus(containerID=null, image=jamesrcounts/variantspark:002, imageID=, lastState=ContainerState(running=null, terminated=null, waiting=null, additionalProperties={}), name=spark-kubernetes-driver, ready=false, restartCount=0, state=ContainerState(running=null, terminated=null, waiting=ContainerStateWaiting(message=null, reason=PodInitializing, additionalProperties={}), additionalProperties={}), additionalProperties={})]\n",
      "2018-09-16 08:42:27 INFO  Client:54 - Waiting for application VariantSparkMediumParquet to finish...\n",
      "2018-09-16 08:42:28 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state: \n",
      "\t pod name: variantsparkmediumparquet-58d581b28f653df791a7ce79e21d9628-driver\n",
      "\t namespace: default\n",
      "\t labels: spark-app-selector -> spark-d0fa92b7b49d44799f3cfb1e2e82e5f1, spark-role -> driver\n",
      "\t pod uid: 707fffa6-b98c-11e8-8a8e-0a0cd35f5fb0\n",
      "\t creation time: 2018-09-16T08:42:26Z\n",
      "\t service account name: spark\n",
      "\t volumes: spark-init-properties, download-jars-volume, download-files-volume, spark-token-l2lzk\n",
      "\t node name: ip-10-0-101-78.us-west-2.compute.internal\n",
      "\t start time: 2018-09-16T08:42:26Z\n",
      "\t container images: jamesrcounts/variantspark:002\n",
      "\t phase: Pending\n",
      "\t status: [ContainerStatus(containerID=null, image=jamesrcounts/variantspark:002, imageID=, lastState=ContainerState(running=null, terminated=null, waiting=null, additionalProperties={}), name=spark-kubernetes-driver, ready=false, restartCount=0, state=ContainerState(running=null, terminated=null, waiting=ContainerStateWaiting(message=null, reason=PodInitializing, additionalProperties={}), additionalProperties={}), additionalProperties={})]\n",
      "2018-09-16 08:42:30 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state: \n",
      "\t pod name: variantsparkmediumparquet-58d581b28f653df791a7ce79e21d9628-driver\n",
      "\t namespace: default\n",
      "\t labels: spark-app-selector -> spark-d0fa92b7b49d44799f3cfb1e2e82e5f1, spark-role -> driver\n",
      "\t pod uid: 707fffa6-b98c-11e8-8a8e-0a0cd35f5fb0\n",
      "\t creation time: 2018-09-16T08:42:26Z\n",
      "\t service account name: spark\n",
      "\t volumes: spark-init-properties, download-jars-volume, download-files-volume, spark-token-l2lzk\n",
      "\t node name: ip-10-0-101-78.us-west-2.compute.internal\n",
      "\t start time: 2018-09-16T08:42:26Z\n",
      "\t container images: jamesrcounts/variantspark:002\n",
      "\t phase: Pending\n",
      "\t status: [ContainerStatus(containerID=null, image=jamesrcounts/variantspark:002, imageID=, lastState=ContainerState(running=null, terminated=null, waiting=null, additionalProperties={}), name=spark-kubernetes-driver, ready=false, restartCount=0, state=ContainerState(running=null, terminated=null, waiting=ContainerStateWaiting(message=null, reason=PodInitializing, additionalProperties={}), additionalProperties={}), additionalProperties={})]\n",
      "2018-09-16 08:42:31 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state: \n",
      "\t pod name: variantsparkmediumparquet-58d581b28f653df791a7ce79e21d9628-driver\n",
      "\t namespace: default\n",
      "\t labels: spark-app-selector -> spark-d0fa92b7b49d44799f3cfb1e2e82e5f1, spark-role -> driver\n",
      "\t pod uid: 707fffa6-b98c-11e8-8a8e-0a0cd35f5fb0\n",
      "\t creation time: 2018-09-16T08:42:26Z\n",
      "\t service account name: spark\n",
      "\t volumes: spark-init-properties, download-jars-volume, download-files-volume, spark-token-l2lzk\n",
      "\t node name: ip-10-0-101-78.us-west-2.compute.internal\n",
      "\t start time: 2018-09-16T08:42:26Z\n",
      "\t container images: jamesrcounts/variantspark:002\n",
      "\t phase: Running\n",
      "\t status: [ContainerStatus(containerID=docker://119b710924002d547d34553bcaf1972c5836b9ea4c9fe15b1c0c00efffe3a609, image=jamesrcounts/variantspark:002, imageID=docker-pullable://jamesrcounts/variantspark@sha256:788155cb91dbd2edc22868377e8102a02cfae98d2a99be93455ab84001d06685, lastState=ContainerState(running=null, terminated=null, waiting=null, additionalProperties={}), name=spark-kubernetes-driver, ready=true, restartCount=0, state=ContainerState(running=ContainerStateRunning(startedAt=Time(time=2018-09-16T08:42:30Z, additionalProperties={}), additionalProperties={}), terminated=null, waiting=null, additionalProperties={}), additionalProperties={})]\n",
      "2018-09-16 08:59:57 INFO  WatchConnectionManager:379 - Current reconnect backoff is 1000 milliseconds (T0)\n",
      "2018-09-16 08:59:58 INFO  LoggingPodStatusWatcherImpl:54 - Container final statuses:\n",
      "\n",
      "\n",
      "\t Container name: spark-kubernetes-driver\n",
      "\t Container image: jamesrcounts/variantspark:002\n",
      "\t Container state: Running\n",
      "\t Container started at: 2018-09-16T08:42:30Z\n",
      "2018-09-16 08:59:58 INFO  Client:54 - Application VariantSparkMediumParquet finished.\n",
      "2018-09-16 08:59:58 INFO  ShutdownHookManager:54 - Shutdown hook called\n",
      "2018-09-16 08:59:58 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-b7393a69-6244-457e-9f3f-c783ab835ba0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "set -e\n",
    "\n",
    "MASTER=https://kubernetes.default.svc:443\n",
    "INPUT_BUCKET=variant-spark\n",
    "\n",
    "function fatal_error () {\n",
    "\techo \"ERROR: $1\" 1>&2\n",
    "\texit 1\n",
    "}\n",
    "\n",
    "if [ -z ${MASTER+x} ];\n",
    "    then\n",
    "        echo \"You must set the MASTER environment variable to a kubernetes API endpoint\";\n",
    "        echo \"Example: https://ABC.sk1.us-west-2.eks.amazonaws.com:443\"\n",
    "        exit 1\n",
    "fi\n",
    "\n",
    "if [ -z ${INPUT_BUCKET+x} ];\n",
    "    then\n",
    "        echo \"You must set the INPUT_BUCKET environment variable to a bucket containing input data\";\n",
    "        echo \"Example: variant-spark-k-storage\"\n",
    "        exit 1\n",
    "fi\n",
    "\n",
    "[[ $(type -P \"spark-submit\") ]] || fatal_error  \"\\`spark-submit\\` cannot be found. Please make sure it's on your PATH.\"\n",
    "\n",
    "spark-submit \\\n",
    "    --class au.csiro.variantspark.cli.VariantSparkApp \\\n",
    "    --driver-class-path ./conf \\\n",
    "    --master k8s://${MASTER} \\\n",
    "    --deploy-mode cluster \\\n",
    "    --name VariantSparkMediumParquet \\\n",
    "    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \\\n",
    "    --conf spark.executor.instances=120 \\\n",
    "    --conf spark.executor.memory=7g \\\n",
    "    --conf spark.kubernetes.container.image=jamesrcounts/variantspark:002 \\\n",
    "    --jars http://central.maven.org/maven2/org/apache/hadoop/hadoop-aws/2.7.3/hadoop-aws-2.7.3.jar,http://central.maven.org/maven2/com/amazonaws/aws-java-sdk/1.7.4/aws-java-sdk-1.7.4.jar,http://central.maven.org/maven2/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar \\\n",
    "    local:///opt/spark/jars/variant-spark_2.11-0.2.0-SNAPSHOT-all.jar importance \\\n",
    "        -if s3a://${INPUT_BUCKET}/datasets/synthetic/data_s5000_v100000000_r13.parquet \\\n",
    "        -ff s3a://${INPUT_BUCKET}/datasets/synthetic/labels_s5000_v100000000_r13_f0.125.csv \\\n",
    "        -fc resp \\\n",
    "        -it parquet \\\n",
    "        -v \\\n",
    "        -rn 200 \\\n",
    "        -rbs 28 \\\n",
    "        -ro \"$@\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
