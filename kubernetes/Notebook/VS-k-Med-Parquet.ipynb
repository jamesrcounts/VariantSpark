{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VariantSpark-k Medium Parquet\n",
    " - 5,000 samples  \n",
    " - 100,000,000 variables   \n",
    " - ?? minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "set -e\n",
    "\n",
    "MASTER=https://kubernetes.default.svc:443\n",
    "INPUT_BUCKET=variant-spark\n",
    "\n",
    "function fatal_error () {\n",
    "\techo \"ERROR: $1\" 1>&2\n",
    "\texit 1\n",
    "}\n",
    "\n",
    "if [ -z ${MASTER+x} ];\n",
    "    then\n",
    "        echo \"You must set the MASTER environment variable to a kubernetes API endpoint\";\n",
    "        echo \"Example: https://ABC.sk1.us-west-2.eks.amazonaws.com:443\"\n",
    "        exit 1\n",
    "fi\n",
    "\n",
    "if [ -z ${INPUT_BUCKET+x} ];\n",
    "    then\n",
    "        echo \"You must set the INPUT_BUCKET environment variable to a bucket containing input data\";\n",
    "        echo \"Example: variant-spark-k-storage\"\n",
    "        exit 1\n",
    "fi\n",
    "\n",
    "[[ $(type -P \"spark-submit\") ]] || fatal_error  \"\\`spark-submit\\` cannot be found. Please make sure it's on your PATH.\"\n",
    "\n",
    "spark-submit \\\n",
    "    --class au.csiro.variantspark.cli.VariantSparkApp \\\n",
    "    --driver-class-path ./conf \\\n",
    "    --master k8s://${MASTER} \\\n",
    "    --deploy-mode cluster \\\n",
    "    --name VariantSparkMediumParquet \\\n",
    "    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \\\n",
    "    --conf spark.executor.instances=28 \\\n",
    "    --conf spark.executor.memory=4g \\\n",
    "    --conf spark.kubernetes.container.image=jamesrcounts/variantspark:002 \\\n",
    "    --jars http://central.maven.org/maven2/org/apache/hadoop/hadoop-aws/2.7.3/hadoop-aws-2.7.3.jar,http://central.maven.org/maven2/com/amazonaws/aws-java-sdk/1.7.4/aws-java-sdk-1.7.4.jar,http://central.maven.org/maven2/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar \\\n",
    "    local:///opt/spark/jars/variant-spark_2.11-0.2.0-SNAPSHOT-all.jar importance \\\n",
    "        -if s3a://${INPUT_BUCKET}/datasets/synthetic/data_s5000_v100000000_r13.parquet \\\n",
    "        -ff s3a://${INPUT_BUCKET}/datasets/synthetic/labels_s5000_v100000000_r13_f0.125.csv \\\n",
    "        -fc resp \\\n",
    "        -it parquet\n",
    "        -v \\\n",
    "        -rn 500 \\\n",
    "        -rbs 28 \\\n",
    "        -ro \"$@\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
